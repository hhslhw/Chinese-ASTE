# Chinese-ASTE
ä¸ªäººnlpè¯¾ç¨‹å¤§ä½œä¸šï¼Œé€‰ç”¨Qwen3ä¸Geminiçš„è½»é‡åŒ–æ¨¡å‹å®Œæˆä¸­æ–‡ASTEä»»åŠ¡
ğŸ­ åŸºäº LLM çš„ä¸­æ–‡å±æ€§çº§æƒ…æ„Ÿä¸‰å…ƒç»„æŠ½å– (ASTE)
è‡ªç„¶è¯­è¨€å¤„ç†è¯¾ç¨‹è®¾è®¡ | ä¸Šæµ·æµ·äº‹å¤§å­¦

æ¨¡å‹ï¼š Qwen-1.7B / Qwen-4B / Gemma-4B
æ–¹æ³•ï¼š Zero-shot / Few-shot ICL / LoRA Fine-tuning





ğŸ“– é¡¹ç›®ç®€ä»‹ (Introduction)
æœ¬é¡¹ç›®é’ˆå¯¹ ä¸­æ–‡å±æ€§çº§æƒ…æ„Ÿåˆ†æ (Aspect Sentiment Triplet Extraction, ASTE) ä»»åŠ¡ï¼Œæ¢ç´¢äº†è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹ï¼ˆ<7Bï¼‰çš„æ€§èƒ½è¾¹ç•Œã€‚ä»»åŠ¡ç›®æ ‡æ˜¯ä»éç»“æ„åŒ–è¯„è®ºä¸­æŠ½å– (è¯„ä»·å¯¹è±¡ Aspect, è§‚ç‚¹è¯ Opinion, æƒ…æ„Ÿææ€§ Sentiment) ä¸‰å…ƒç»„ã€‚

æˆ‘ä»¬åŸºäº Qwen (é€šä¹‰åƒé—®) å’Œ Gemma ç³»åˆ—æ¨¡å‹ï¼Œç³»ç»Ÿå¯¹æ¯”äº†é›¶æ ·æœ¬æ¨ç† (Zero-shot)ã€å°‘æ ·æœ¬å­¦ä¹  (Few-shot) ä»¥åŠ LoRA æŒ‡ä»¤å¾®è°ƒçš„æ•ˆæœã€‚å®éªŒè¯æ˜ï¼Œé€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œ1.7B çš„å°æ¨¡å‹åœ¨å‚ç›´é¢†åŸŸçš„ç»“æ„åŒ–æŠ½å–ä»»åŠ¡ä¸Šå¯ä»¥è¾¾åˆ°å·¥ä¸šçº§å¯ç”¨æ°´å¹³ã€‚

âœ¨ æ ¸å¿ƒç‰¹æ€§ (Key Features)
å¤šæ¨¡å‹å¯¹æ¯”ï¼šæ¨ªå‘æµ‹è¯„ Qwen-1.7B, Qwen-4B ä¸ Google Gemma-4Bï¼ŒéªŒè¯äº†å›½äº§æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸‹çš„ä¼˜åŠ¿ã€‚
å…¨æµç¨‹èŒƒå¼ï¼šæ¶µç›– Prompt Engineering (Zero/Few-shot) ä¸ Parameter-Efficient Fine-Tuning (LoRA)ã€‚
æ·±åº¦æ¶ˆèå®éªŒï¼š
Prompt æ¶ˆèï¼šæ¢ç©¶ä»»åŠ¡å®šä¹‰ä¸è§’è‰²æ‰®æ¼”å¯¹æŒ‡ä»¤éµå¾ªçš„å½±å“ã€‚
Rank æ¶ˆèï¼šå¯¹æ¯” 
ğ‘Ÿ
=
16
r=16 ä¸ 
ğ‘Ÿ
=
64
r=64ï¼Œå‘ç°ä½ç§©è®¾ç½®èƒ½æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
åŒé‡è¯„ä¼°ä½“ç³»ï¼šè®¾è®¡ Strict (ä¸¥æ ¼åŒ¹é…) ä¸ Soft (æ¨¡ç³ŠåŒ¹é…) åŒæŒ‡æ ‡ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ•°æ®é›†æ ‡æ³¨æ»åå¸¦æ¥çš„â€œå‡é˜³æ€§æ‚–è®ºâ€ã€‚
ğŸ“‚ æ–‡ä»¶ç»“æ„ (File Structure)
<BASH>
.
â”œâ”€â”€ data/                   # æ•°æ®é›†æ–‡ä»¶å¤¹ (chn_review_aste)
â”‚   â”œâ”€â”€ train.json          # è®­ç»ƒé›†
â”‚   â”œâ”€â”€ test.json           # æµ‹è¯•é›†
â”‚   â””â”€â”€ dev.json            # éªŒè¯é›†
â”œâ”€â”€ output/                 # æ¨¡å‹æ¨ç†è¾“å‡ºç»“æœ (.jsonl)
â”œâ”€â”€ src/                    # æºä»£ç 
â”‚   â”œâ”€â”€ train.py            # LoRA å¾®è°ƒè®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ inference.py        # æ¨¡å‹æ¨ç†è„šæœ¬
â”‚   â”œâ”€â”€ evaluation.py       # è¯„ä¼°è„šæœ¬ (è®¡ç®— Precision/Recall/F1)
â”‚   â””â”€â”€ utils.py            # æ•°æ®é¢„å¤„ç†ä¸Promptæ„å»ºå·¥å…·
â”œâ”€â”€ report/                 # è¯¾ç¨‹è®¾è®¡æŠ¥å‘Šä¸åˆ†æå›¾è¡¨
â”œâ”€â”€ requirements.txt        # ç¯å¢ƒä¾èµ–
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡æ¡£
ğŸš€ å¿«é€Ÿå¼€å§‹ (Getting Started)
1. ç¯å¢ƒå®‰è£…
å»ºè®®ä½¿ç”¨ Conda åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼š

<BASH>
conda create -n aste_llm python=3.10
conda activate aste_llm
pip install -r requirements.txt
ä¸»è¦ä¾èµ–åº“ï¼štorch, transformers, peft, accelerate, bitsandbytes.

2. LoRA å¾®è°ƒ (Training)
è¿è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨ Qwen-4B çš„ LoRA å¾®è°ƒï¼š

<BASH>
python src/train.py \
    --model_name_or_path "Qwen/Qwen-4B" \
    --data_path "data/train.json" \
    --output_dir "checkpoints/qwen_lora" \
    --lora_rank 16 \
    --lora_alpha 32 \
    --batch_size 4 \
    --gradient_accumulation_steps 4
3. æ¨ç†ä¸è¯„ä¼° (Evaluation)
å¾®è°ƒåè¿›è¡Œæ¨ç†å¹¶ç”Ÿæˆè¯„ä¼°æŠ¥å‘Šï¼š

<BASH>
# ç”Ÿæˆæ¨ç†ç»“æœ
python src/inference.py --model_path "checkpoints/qwen_lora" --test_data "data/test.json"
# è®¡ç®—æŒ‡æ ‡
python src/evaluation.py --pred_file "output/output_Qwen_4B_lora.jsonl"
ğŸ“Š å®éªŒç»“æœ (Results)
æˆ‘ä»¬åœ¨ chn_review_aste æ•°æ®é›†ä¸Šè¿›è¡Œäº†å…¨é¢æµ‹è¯•ã€‚ä»¥ä¸‹æ˜¯ Qwen-4B æ¨¡å‹çš„ä¸»è¦æŒ‡æ ‡å¯¹æ¯”ï¼š

æ–¹æ³• (Method)	Strict Precision	Strict Recall	Strict F1	Soft F1
Zero-shot	17.61%	26.31%	20.19%	53.27%
Few-shot (4-shot)	19.89%	29.45%	22.46%	53.26%
LoRA (r=16)	71.78%	84.77%	75.64%	79.40%
ç»“è®ºï¼š LoRA å¾®è°ƒåçš„ Strict F1 ç›¸æ¯” Zero-shot æå‡äº†çº¦ 3.7å€ã€‚

ğŸ” æ¶ˆèåˆ†æäº®ç‚¹
LoRA Rank é€‰æ‹©ï¼šå®éªŒå‘ç° 
ğ‘Ÿ
=
16
r=16 (F1=0.7564) ä¼˜äº 
ğ‘Ÿ
=
64
r=64 (F1=0.7150)ã€‚è¯æ˜äº† ASTE ä»»åŠ¡å…·æœ‰ä½å†…åœ¨ç»´åº¦ï¼Œè¿‡é«˜çš„ç§©ä¼šå¯¼è‡´è¿‡æ‹Ÿåˆã€‚
æ¨¡å‹é€‰å‹ï¼šåœ¨ç›¸åŒå¾®è°ƒè®¾ç½®ä¸‹ï¼ŒQwen-1.7B (F1=0.71) æ˜¾è‘—ä¼˜äº Gemma-4B (F1=0.64)ï¼Œè¡¨æ˜åŸºåº§æ¨¡å‹çš„è¯­è¨€åˆ†å¸ƒï¼ˆä¸­æ–‡è¯­æ–™å æ¯”ï¼‰å¯¹ä¸­æ–‡ä»»åŠ¡è‡³å…³é‡è¦ã€‚
ğŸ“ å¼•ç”¨ä¸è‡´è°¢ (Credits)
æœ¬é¡¹ç›®æ˜¯ä¸Šæµ·æµ·äº‹å¤§å­¦ã€Šè‡ªç„¶è¯­è¨€å¤„ç†ã€‹è¯¾ç¨‹è®¾è®¡ä½œå“ã€‚

ä½œè€…ï¼š é»‘å‘é˜³ (ç®—æ³•/è®­ç»ƒ), ç‹ä¿Šçš“ (è¯„ä¼°/å·¥ç¨‹)
æŒ‡å¯¼æ•™å¸ˆï¼š è°¢é›¨æ³¢
æ•°æ®é›†æ¥æºï¼š Automated Construction of Chinese ASTE Dataset
å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿æäº¤ Issue æˆ–è”ç³»ä½œè€…ã€‚
